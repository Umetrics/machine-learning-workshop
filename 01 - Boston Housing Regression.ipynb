{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A real machine learning pipeline\n",
    "\n",
    "In this notebook we will demonstrate how scikit-learn can be used to assemble a complete machine learning pipeline to predict house prices on the Boston housing dataset. By using the [`Pipeline`](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html)-class we can stitch together pre-processing and model fitting in a very convenient way. \n",
    "\n",
    "Using the pipelining we also avoid data leakage. Probably the most common reason for data leakage is that preprocessing steps are accidentally fitted on both train- and test-data. If we for instance use standard scaling as preprocessing, such mistake would mean that the variables are scaled using parameters calculated partly on the test-set. This means that the model will get access to \"knowledge\" leaked from the test-set into the training, which may give a overly optimistic evaluation.\n",
    "\n",
    "We don't want optimistic evaluations, we want honest ones so we can report honest results back to our managers.\n",
    "\n",
    "**Feel free to explore other regression models in your own cells before**\n",
    "\n",
    "The scikit-learn user guide has plenty of information on different [regression](https://scikit-learn.org/stable/supervised_learning.html#supervised-learning) and [preprocessing](https://scikit-learn.org/stable/modules/preprocessing.html#preprocessing) methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.metrics import mean_squared_error, make_scorer\n",
    "from sklearn.linear_model import LinearRegression, RidgeCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we read our data and split out response to separate series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('boston-housing.csv')\n",
    "\n",
    "response = df['target']\n",
    "df.drop('target', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We split out 30 \\% of the data to use for validating our model.\n",
    "\n",
    "We are not aware of any dependencies in our data, so we make the split randomly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1337)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(df, response, test_size=.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we define a convenience-function that we will use to cross-validate our pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossvalidated_mean_squared_error(regressor, x, y):\n",
    "    scoring_fn = make_scorer(mean_squared_error)\n",
    "    fold_scores = cross_val_score(regressor, x, y, cv=5, scoring=scoring_fn)\n",
    "    return fold_scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1st attempt - Linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start simple, with a linear regression using all variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Square Error averaged accross cross-validation: 20.3953453272921\n"
     ]
    }
   ],
   "source": [
    "lr_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('model', LinearRegression())\n",
    "])\n",
    "\n",
    "mse_cv = crossvalidated_mean_squared_error(lr_pipeline, x_train, y_train)\n",
    "\n",
    "print(f'Mean Square Error averaged accross cross-validation: {mse_cv}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2nd attempt - Polynomial regression\n",
    "\n",
    "To see if we can improve our results, we may include polynomial terms as well (square terms and interactions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Square Error averaged accross cross-validation: 41.239820413420496\n"
     ]
    }
   ],
   "source": [
    "poly_lr_pipeline = Pipeline([\n",
    "    ('polynomial', PolynomialFeatures()),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('model', LinearRegression())\n",
    "])\n",
    "\n",
    "mse_cv = crossvalidated_mean_squared_error(poly_lr_pipeline, x_train, y_train)\n",
    "\n",
    "print(f'Mean Square Error averaged accross cross-validation: {mse_cv}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whoops. Error is twice as large using simple regression with polynomial features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3rd attempt - Polynomial features with Ridge regression\n",
    "\n",
    "Our naive attempt on polynomial features was probably due to overfitting. We try to use Ridge regression, which is a popular method to combat overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Square Error averaged accross cross-validation: 11.30858850179826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RickardS\\Anaconda3\\envs\\umejug-env\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\RickardS\\Anaconda3\\envs\\umejug-env\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\RickardS\\Anaconda3\\envs\\umejug-env\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "poly_ridge_pipeline = Pipeline([\n",
    "    ('polynomial', PolynomialFeatures()),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('model', RidgeCV(cv=3))\n",
    "])\n",
    "\n",
    "mse_cv = crossvalidated_mean_squared_error(poly_ridge_pipeline, x_train, y_train)\n",
    "\n",
    "print(f'Mean Square Error averaged accross cross-validation: {mse_cv}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results\n",
    "\n",
    "According to cross-validation, our best model is to use polynomial features combined with ridge regression.\n",
    "\n",
    "We therefore fit our final model on all training data and report test-set performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test-set Mean Square Error: 20.138701207866074\n"
     ]
    }
   ],
   "source": [
    "poly_ridge_pipeline.fit(x_train, y_train)\n",
    "\n",
    "test_mean_squared_error = mean_squared_error(y_test, poly_ridge_pipeline.predict(x_test))\n",
    "\n",
    "print(f'Test-set Mean Square Error: {test_mean_squared_error}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the test-set error is quite a bit higher than the validation error. This is common, and it is the most honest estimate you get.\n",
    "\n",
    "**Don't look at test-set error before deciding which model to use!**\n",
    "You want to know roughly how well the model will work in the future. The model is supposed to be the one you actually think works best. NOT the one that just happen to perform best on this particular train-test split.\n",
    "\n",
    "Lastly, we persist our model on disk so we can use it in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('boston-housing_polynomial-ridge.pickle', 'wb') as f:\n",
    "    pickle.dump(poly_ridge_pipeline, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Your attempts\n",
    "\n",
    "Follow the structure of the examples above and try to implement your own pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
